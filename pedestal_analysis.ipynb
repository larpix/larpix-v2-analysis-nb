{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data analysis\n",
    "Plots summary of channel ADC values and trigger rates\n",
    "\n",
    "## Paths\n",
    "Set ``geometrypath`` to point to the larpix-geometry yaml file you'd like to use to plot x,y positions of pixels\n",
    "Set ``datapath`` to point to the directory containing datafiles you'd like to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as colors\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import yaml\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometrypath = '/global/project/projectdirs/dune/users/pmadigan/larpix/larpix-software/larpix-geometry/larpixgeometry/layouts/layout-2.4.0.yaml'\n",
    "# datapath = '/global/project/projectdirs/dune/data/larpix/raw_data/raw_20_10_12/500_V_cm'\n",
    "datapath = '/global/project/projectdirs/dune/www/data/Bern-singlecube/LArPix/dataRuns/rawData' # data runs\n",
    "# datapath = '/global/project/projectdirs/dune/www/data/Bern-singlecube/LArPix/pedestalRuns' # pedestal runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconfig_files\u001b[0m/  evd_config_20-10-26_10-48-37.json  \u001b[01;34mpedestalRuns\u001b[0m/  \u001b[01;34mthresholds\u001b[0m/\n",
      "\u001b[01;34mdataRuns\u001b[0m/      \u001b[01;34mleakageCurrent\u001b[0m/                    \u001b[01;34mpulser\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /global/project/projectdirs/dune/www/data/Bern-singlecube/LArPix/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cache\n",
    "Evaluate this cell to refresh stored data from run files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c42405e7b34f69997522b0b7870cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='File', options=('datalog_2020_10_26_17_18_45_CET_.h5', 'dataâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "files = sorted([os.path.basename(path) for path in glob.glob(datapath+'/*_.h5')])\n",
    "\n",
    "def unique_channel_id(d):\n",
    "    return ((d['io_group'].astype(int)*256 + d['io_channel'].astype(int))*256 \\\n",
    "            + d['chip_id'].astype(int))*64 + d['channel_id'].astype(int)\n",
    "def unique_channel_id_2_str(unique_id,*args,**kwargs):\n",
    "    return (unique_id//(256*256*64)).astype(int).astype(str) \\\n",
    "        + '-' + ((unique_id//(256*64))%256).astype(int).astype(str) \\\n",
    "        + '-' + ((unique_id//64)%256).astype(int).astype(str) \\\n",
    "        + '-' + (unique_id%64).astype(int).astype(str)\n",
    "\n",
    "with open(geometrypath) as fi:\n",
    "    geo = yaml.full_load(fi)\n",
    "chip_pix = dict([(chip_id, pix) for chip_id,pix in geo['chips']])\n",
    "\n",
    "@widgets.interact\n",
    "def display(filenames=widgets.SelectMultiple(options=files, rows=10, description=\"File\")\n",
    "           ):   \n",
    "    plt.close('all')\n",
    "    fig1 = None\n",
    "    for filename in filenames:\n",
    "        if not filename in data_cache:\n",
    "            print('opening',filename,'...')\n",
    "            f = h5py.File(os.path.join(datapath,filename),'r')\n",
    "            unixtime = f['packets']['timestamp'][f['packets']['packet_type'] == 4]\n",
    "            livetime = np.max(unixtime) - np.min(unixtime)\n",
    "\n",
    "            data_mask = f['packets']['packet_type'] == 0\n",
    "            data_mask = np.logical_and(f['packets']['valid_parity'], data_mask)\n",
    "            dataword = f['packets']['dataword'][data_mask]\n",
    "\n",
    "            unique_id = unique_channel_id(f['packets'][data_mask])\n",
    "            unique_id_set = np.unique(unique_id)\n",
    "            d = defaultdict(dict)\n",
    "            last = time.time()\n",
    "            for i,id in enumerate(unique_id_set):\n",
    "                if time.time() > last + 1:\n",
    "                    print('{}/{} {}'.format(i+1,len(unique_id_set),unique_channel_id_2_str(id)),end='\\r')\n",
    "                    last = time.time()\n",
    "                id_mask = unique_id == id\n",
    "                if np.sum(id_mask) < 3:\n",
    "                    continue\n",
    "                masked_dataword = dataword[id_mask]\n",
    "                d[id]['min'] = np.min(masked_dataword)\n",
    "                d[id]['mean'] = np.mean(masked_dataword)\n",
    "                d[id]['med'] = np.median(masked_dataword)\n",
    "                d[id]['std'] = np.std(masked_dataword)\n",
    "                d[id]['rate'] = len(masked_dataword) / (livetime + 1e-9)\n",
    "                pix = chip_pix[(id//64)%256][id%64] if (id//64)%256 in chip_pix else None\n",
    "                if pix:\n",
    "                    d[id]['x'] = geo['pixels'][pix][1]\n",
    "                    d[id]['y'] = geo['pixels'][pix][2]\n",
    "                else:\n",
    "                    d[id]['x'] = 0.\n",
    "                    d[id]['y'] = 0.\n",
    "            data_cache[filename] = d\n",
    "        else:\n",
    "            print('loading',filename,'from cache')\n",
    "            d = data_cache[filename]\n",
    "\n",
    "        if not fig1:\n",
    "            fig1,axes = plt.subplots(3,1,sharex='col',num='summary 1',figsize=(8,6))\n",
    "        else:\n",
    "            fig1 = plt.figure('summary 1')\n",
    "            axes = fig1.axes\n",
    "        axes[0].scatter([key for key in d if 'mean' in d[key]],\n",
    "                        [d[key]['mean'] for key in d if 'mean' in d[key]],\n",
    "                        marker='.',alpha=0.5)\n",
    "        axes[1].scatter([key for key in d if 'std' in d[key]],\n",
    "                        [d[key]['std'] for key in d if 'std' in d[key]],\n",
    "                        marker='.',alpha=0.5)\n",
    "        axes[2].scatter([key for key in d if 'rate' in d[key]],\n",
    "                        [d[key]['rate'] for key in d if 'rate' in d[key]],\n",
    "                        marker='.',alpha=0.5)\n",
    "        axes[2].set(xlabel='unique channel')\n",
    "        axes[0].set(ylabel='mean ADC')\n",
    "        axes[1].set(ylabel='std ADC')\n",
    "        axes[2].set(ylabel='rate [Hz]')\n",
    "        for ax in axes:\n",
    "            ax.grid(1)\n",
    "        axes[2].set_yscale('log')\n",
    "\n",
    "        ax2 = axes[0].secondary_xaxis('top', functions=(lambda x: x, lambda x: x))\n",
    "        ax2.xaxis.set_major_formatter(ticker.FuncFormatter(unique_channel_id_2_str))\n",
    "        ax2.set(xlabel='channel key')\n",
    "        plt.legend(range(len(filenames)))\n",
    "        plt.tight_layout()\n",
    "\n",
    "        fig2, axes = plt.subplots(3,1,sharex='col',sharey='col',num='summary 2 {}'.format(filename),figsize=(6,12))\n",
    "        x = np.array([d[key]['x'] for key in d if 'x' in d[key]])\n",
    "        y = np.array([d[key]['y'] for key in d if 'y' in d[key]])\n",
    "        c0 = fig2.colorbar(axes[0].scatter(x,y,c=[d[key]['mean'] for key in d if 'mean' in d[key]], \n",
    "                                           marker='.', alpha=0.5*2), ax=axes[0])\n",
    "        c1 = fig2.colorbar(axes[1].scatter(x,y,c=[d[key]['std'] for key in d if 'std' in d[key]], \n",
    "                                           marker='.', norm=colors.LogNorm(), alpha=0.5*2), ax=axes[1])\n",
    "        c2 = fig2.colorbar(axes[2].scatter(x,y,c=[d[key]['rate'] for key in d if 'rate' in d[key]], \n",
    "                                           marker='.', norm=colors.LogNorm(), alpha=0.5*2), ax=axes[2])\n",
    "        axes[2].set(xlabel='x [mm]')\n",
    "        axes[0].set(ylabel='y [mm]',title=filename)\n",
    "        c0.set_label('mean ADC')\n",
    "        axes[1].set(ylabel='y [mm]')\n",
    "        c1.set_label('std ADC')\n",
    "        axes[2].set(ylabel='y [mm]')\n",
    "        c2.set_label('rate [Hz]')\n",
    "\n",
    "        ax2 = axes[0].secondary_xaxis('top', functions=(lambda x: x, lambda x: x))\n",
    "        ax2.set(xlabel='x [mm]')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        for filename_other in filenames:\n",
    "            figname='correlation {},{}'.format(filename, filename_other)\n",
    "            if filename_other == filename:\n",
    "                continue\n",
    "            elif filename_other not in data_cache:\n",
    "                continue\n",
    "            elif plt.fignum_exists(figname):\n",
    "                continue\n",
    "            d_other = data_cache[filename_other]\n",
    "            fig,axes = plt.subplots(3,1,num=figname, figsize=(6,12))\n",
    "            axes[0].scatter([d_other[key]['mean'] for key in d if 'mean' in d[key] and 'mean' in d_other[key]],\n",
    "                            [d[key]['mean'] for key in d if 'mean' in d[key] and 'mean' in d_other[key]],\n",
    "                            marker='.',alpha=0.5)\n",
    "            axes[1].scatter([d_other[key]['std'] for key in d if 'std' in d[key] and 'std' in d_other[key]],\n",
    "                            [d[key]['std'] for key in d if 'std' in d[key] and 'std' in d_other[key]],\n",
    "                            marker='.',alpha=0.5)\n",
    "            axes[2].scatter([d_other[key]['rate'] for key in d if 'rate' in d[key] and 'rate' in d_other[key]],\n",
    "                            [d[key]['rate'] for key in d if 'rate' in d[key] and 'rate' in d_other[key]],\n",
    "                            marker='.',alpha=0.5)\n",
    "            axes[0].set(xlabel='mean ADC, {}'.format(filename_other), ylabel='mean ADC, {}'.format(filename))\n",
    "            axes[1].set(xlabel='std ADC, {}'.format(filename_other), ylabel='std ADC, {}'.format(filename))\n",
    "            axes[2].set(xlabel='rate [Hz], {}'.format(filename_other), ylabel='rate [Hz], {}'.format(filename))\n",
    "            for ax in axes:\n",
    "                ax.grid(1)\n",
    "            plt.tight_layout()\n",
    "                \n",
    "    # aggregate\n",
    "    if filenames:\n",
    "        all_d = defaultdict(lambda : defaultdict(float))\n",
    "        ids = set([id for filename in filenames for id in data_cache[filename]])\n",
    "        for id in ids:\n",
    "            for attr in ('min','mean','med','std','rate','x','y'):\n",
    "                f = np.mean\n",
    "                if attr in ('x','y'):\n",
    "                    f = np.median\n",
    "                all_d[id][attr] = f([data_cache[filename][id][attr] for filename in filenames \n",
    "                                     if id in data_cache[filename] and attr in data_cache[filename][id]])\n",
    "\n",
    "        fig_agg2, axes = plt.subplots(3,1,sharex='col',sharey='col',num='summary 2 all',figsize=(6,12))\n",
    "        x = np.array([all_d[id]['x'] for id in ids])\n",
    "        y = np.array([all_d[id]['y'] for id in ids])\n",
    "        c0 = fig_agg2.colorbar(axes[0].scatter(x,y,c=[all_d[id]['mean'] for id in ids], \n",
    "                                               marker='.', alpha=0.5*2), ax=axes[0])\n",
    "        c1 = fig_agg2.colorbar(axes[1].scatter(x,y,c=[all_d[id]['std'] for id in ids], \n",
    "                                               marker='.', norm=colors.LogNorm(), alpha=0.5*2), ax=axes[1])\n",
    "        c2 = fig_agg2.colorbar(axes[2].scatter(x,y,c=[all_d[id]['rate'] for id in ids], \n",
    "                                               marker='.', norm=colors.LogNorm(), alpha=0.5*2), ax=axes[2])\n",
    "        axes[2].set(xlabel='x [mm]')\n",
    "        axes[0].set(ylabel='y [mm]',title=filename)\n",
    "        c0.set_label('mean ADC')\n",
    "        axes[1].set(ylabel='y [mm]')\n",
    "        c1.set_label('std ADC')\n",
    "        axes[2].set(ylabel='y [mm]')\n",
    "        c2.set_label('rate [Hz]')\n",
    "\n",
    "        ax2 = axes[0].secondary_xaxis('top', functions=(lambda x: x, lambda x: x))\n",
    "        ax2.set(xlabel='x [mm]')\n",
    "        plt.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datalog_2020_10_27_04_19_20_CET_.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-085f0a10b69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'datalog_2020_10_27_04_19_20_CET_.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chip'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'chan'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Hz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datalog_2020_10_27_04_19_20_CET_.h5'"
     ]
    }
   ],
   "source": [
    "run = 'datalog_2020_10_27_04_19_20_CET_.h5'\n",
    "for channel,vals in data_cache[run].items():\n",
    "    if vals['rate'] > 5:\n",
    "        print('chip',(channel//64)%256,'chan',(channel%64),vals['rate'],'Hz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
